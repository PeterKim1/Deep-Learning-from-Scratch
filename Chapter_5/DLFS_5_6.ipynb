{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLFS_5_6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93DqapEWqNQx"
      },
      "source": [
        "# 5.6 Affine/Softmax 계층 구현하기\r\n",
        "## 5.6.1 Affine 계층(p. 171)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j-gEP-jqLGB"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "class Affine:\r\n",
        "    def __init__(self, W, b):\r\n",
        "        # class를 만들 때, W와 b를 지정하고 시작하게 됨\r\n",
        "        self.W = W\r\n",
        "        self.b = b\r\n",
        "        self.x = None\r\n",
        "        self.dW = None\r\n",
        "        self.db = None\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        self.x = x\r\n",
        "        out = np.dot(x, self.W) + self.b\r\n",
        "        return out\r\n",
        "\r\n",
        "    def backward(self, dout):\r\n",
        "        dx = np.dot(dout, self.W.T)\r\n",
        "        self.dW = np.dot(self.x.T, dout)\r\n",
        "        self.db = np.sum(dout, axis = 0)\r\n",
        "\r\n",
        "        return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EG_e-E3eOG9"
      },
      "source": [
        "def softmax(x):\r\n",
        "    c = np.max(x)\r\n",
        "    x_ = np.exp(x - c)\r\n",
        "    y = x_ / np.sum(x_)\r\n",
        "    return y\r\n",
        "\r\n",
        "def cross_entropy_error(y, t):\r\n",
        "    if y.ndim == 1:\r\n",
        "       t = t.reshape(1, t.size)\r\n",
        "       y = y.reshape(1, y.size)\r\n",
        "\r\n",
        "    batch_size = y.shape[0]\r\n",
        "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXCcpM7L472c"
      },
      "source": [
        "class SoftmaxWithLoss:\r\n",
        "    def __init__(self):\r\n",
        "        self.loss = None\r\n",
        "        self.y = None\r\n",
        "        self.t = None\r\n",
        "\r\n",
        "    def forward(self, x, t):\r\n",
        "        self.t = t\r\n",
        "        self.y = softmax(x)\r\n",
        "        print(\"self.y :\", self.y)\r\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\r\n",
        "        return self.loss\r\n",
        "    \r\n",
        "    def backward(self, dout=1):\r\n",
        "        batch_size = self.t.shape[0]\r\n",
        "        dx = (self.y - self.t) / batch_size\r\n",
        "\r\n",
        "        return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HAYfSLok_vV",
        "outputId": "27270735-04ea-49e7-edf9-6a0ec7a779ad"
      },
      "source": [
        "# 예시로 돌려보기\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "SlLayer = SoftmaxWithLoss()\r\n",
        "\r\n",
        "\r\n",
        "# input\r\n",
        "x_ = np.array([[0.1, 0.6, 0.3], [0.2, 0.2, 0.6],[0.05, 0.05, 0.9]])\r\n",
        "# 정답\r\n",
        "t_ = np.array([[0, 0, 1], [0, 1, 0], [0, 0, 1]])\r\n",
        "\r\n",
        "\r\n",
        "# cross entropy error\r\n",
        "loss_1 = SlLayer.forward(x_, t_)\r\n",
        "print(\"Cross Entropy Error: \", loss_1)\r\n",
        "dx = SlLayer.backward()\r\n",
        "print(\"dx: \", dx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "self.y : [[0.08433704 0.13904827 0.10300949]\n",
            " [0.09320684 0.09320684 0.13904827]\n",
            " [0.08022387 0.08022387 0.18769553]]\n",
            "Cross Entropy Error:  2.1062666488247532\n",
            "dx:  [[ 0.02811235  0.04634942 -0.29899684]\n",
            " [ 0.03106895 -0.30226439  0.04634942]\n",
            " [ 0.02674129  0.02674129 -0.27076816]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_lPskL33vJd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}