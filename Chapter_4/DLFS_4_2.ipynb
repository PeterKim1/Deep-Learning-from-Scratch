{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLFS_4.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sMsQBQF61zo"
      },
      "source": [
        "# 4.2 손실함수(p. 111)\r\n",
        "\r\n",
        "신경망 학습에서 사용하는 손실 함수에 대해서 알아본다.\r\n",
        "\r\n",
        "신경망 학습에서는 현재의 상태를 하나의 지표로 표현한다.\r\n",
        "\r\n",
        "## 4.2.1 오차제곱합"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zalfpG3p3v21",
        "outputId": "921922da-26a3-4a0c-d063-6b95d5a1ec93"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# y : 신경망의 출력, t : 정답 레이블\r\n",
        "def sum_squares_error(y, t):\r\n",
        "    return 1/2 * np.sum((y-t)**2)\r\n",
        "\r\n",
        "# 첫 번째 케이스\r\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] \r\n",
        "\r\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\r\n",
        "sum_squares_error(np.array(y), np.array(t)) # 정답에 대해서 0.6으로 예측했을 때"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09750000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpmgBxhA7jiE",
        "outputId": "c1ef4e52-7648-4eb5-d763-26f2e8488942"
      },
      "source": [
        "# 두 번째 케이스\r\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "\r\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\r\n",
        "sum_squares_error(np.array(y), np.array(t)) # 정답에 대해서 0.1로 예측했을 때"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVARk7my8WkM"
      },
      "source": [
        "정답에 대해서 0.6으로 예측했을 때는 에러값이 0.0975, 정답에 대해서 0.1로 예측했을 때 에러값은 0.5975로, 못 맞췄을 때 error 값이 훨씬 크다.\r\n",
        "\r\n",
        "오차제곱합 기준으로는 첫 번째 추정 결과가 에러값이 더 작으므로 정답에 더 가까울 것으로 판단할 수 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "594IHgPk8ueT"
      },
      "source": [
        "## 4.2.2 교차 엔트로피 오차(p. 113)\r\n",
        "\r\n",
        "E = - sigma(t_k * logy_k) 로 표현될 수 있으며, 일반적으로는 classification에서 사용됨.\r\n",
        "\r\n",
        "t_k가 정답 레이블이고, y_k가 신경망의 출력인데 교차 엔트로피 오차의 특징은 정답이 아닌 index의 예측값은 의미가 없다는 것. (one-hot encoding에 의해 정답이 아닌 index는 전부 0이라서 곱해지면 0이 되어버리기 때문)\r\n",
        "\r\n",
        "그리고 교차 엔트로피 오차는 정답에 대해서 100%로 (예측값 상으로는 1로) 맞추도록 만드는 경향이 있다는 점. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msRWZpgX8VyW"
      },
      "source": [
        "# cross entropy error\r\n",
        "# 혹시나 예측값이 0이면, log(0)이 되어버리므로 이를 방지하기 위해 delta를 더해줌\r\n",
        "# 어차피 delta는 매우 작은 값이기 때문에 실제 loss 계산에 큰 영향을 주지 않는다.\r\n",
        "def cross_entropy_error(y, t):\r\n",
        "    delta = 1e-7\r\n",
        "    return -np.sum(t * np.log(y + delta))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVrlg__v-NQQ",
        "outputId": "a2ee4379-be65-4b54-88e9-46ea4957cf2f"
      },
      "source": [
        "# 첫 번째 케이스\r\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "\r\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\r\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.510825457099338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_8jqAl1-Qd3",
        "outputId": "223956a6-d6a7-4467-a9b0-03b535f1d7a0"
      },
      "source": [
        "# 두 번째 케이스\r\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "\r\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\r\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.302584092994546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNr7oRXT-ThQ"
      },
      "source": [
        "정답을 0.6의 예측값으로 맞췄을 때, CE는 0.51, 정답을 0.1의 예측값으로 맞췄을 때, CE는 2.3로 나타남.\r\n",
        "\r\n",
        "CE가 작을수록, 정답인 label을 1에 가깝게 예측한다는 의미가 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrMT40b6-gy4"
      },
      "source": [
        "## 4.2.3 미니배치 학습(p. 115)\r\n",
        "\r\n",
        "데이터를 배치 단위로 연산할 때, 배치 단위로 손실함수를 구해보자.\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)\r\n",
        "\r\n",
        "t_nk는 n번째 데이터의 k번째 값을 의미.\r\n",
        "1개에 대해서 CE를 구하던 식하고 큰 차이는 없으나, 이제는 N개에 대해서 CE를 구하기 때문에 이를 N개로 나눠주어 평균 손실 함수를 계산한다는 점에서만 차이가 존재한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR2QCTKX-TJH"
      },
      "source": [
        "# MNIST 데이터 다시 받아주자. \r\n",
        "# 이미 .gz파일은 저장되어 있다면, 해당 코드는 안 돌려도 상관 없음.\r\n",
        "\r\n",
        "import pickle, gzip, numpy, urllib.request, json, os\r\n",
        "\r\n",
        "# url_base : mnist 데이터가 있는 기본 url\r\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\r\n",
        "\r\n",
        "# mnist 데이터를 저장하고 싶은 위치, 원하는 위치로 지정하면 됨.\r\n",
        "save_folder = '/content/mnist/'\r\n",
        "\r\n",
        "# mnist의 기본 url에서 추가적으로 붙여줘야 하는 파일명들\r\n",
        "# train-images-idx3-ubyte.gz : training image\r\n",
        "# train-labels-idx1-ubyte.gz : training label\r\n",
        "# t10k-images-idx3-ubyte.gz : test image\r\n",
        "# t10k-labels-idx1-ubyte.gz : test label\r\n",
        "key_file = ['train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\r\n",
        "\r\n",
        "\r\n",
        "# urlretrieve : 첫 번째 인자: url 위치, 두 번째 인자: the file location to copy to\r\n",
        "# training image, training label, test image, test label을 다운받아보자.\r\n",
        "for file_name in key_file:\r\n",
        "    urllib.request.urlretrieve(os.path.join(url_base, file_name), os.path.join(save_folder, file_name))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMRFPh7o_pvb",
        "outputId": "e30dd7de-4b73-40ed-bfac-066a2427e891"
      },
      "source": [
        "import gzip\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# 받은 .gz 파일들을 오픈해보자.\r\n",
        "# np.frombuffer가 아닌, f.read()로만 받게 되면 bytes 데이터가 되며, 이렇게 된 경우 우리가 쓸 수 없다.\r\n",
        "# 따라서, 이를 numpy array로 바꿔주는 것이 바로 np.frombuffer이다.\r\n",
        "# 참고자료: https://d-tail.tistory.com/32\r\n",
        "# offset은 어디부터 데이터를 읽을지를 나타내는데, mnist 데이터 설명에 따르면\r\n",
        "# Image의 경우, offset을 16으로 설정해야 하는 것 같다. (그 이전은 다른 값들인듯)\r\n",
        "with gzip.open('/content/mnist/train-images-idx3-ubyte.gz', 'rb') as f:\r\n",
        "    x_train = np.frombuffer(f.read(), dtype = np.uint8, offset = 16)\r\n",
        "\r\n",
        "# x_train은 numpy array 상태이며, 1차원 값으로 되어 있다.\r\n",
        "# 따라서, 이를 28 x 28 형태로 만들어주기 위해 .reshape를 진행하게 되며,\r\n",
        "# 이에 따라 shape는 60000, 784로 바뀌게 된다. 즉, training image는 6만장이다.\r\n",
        "x_train = x_train.reshape(-1, 28 * 28)\r\n",
        "print(x_train.shape)\r\n",
        "\r\n",
        "with gzip.open('/content/mnist/train-labels-idx1-ubyte.gz', 'rb') as f:\r\n",
        "    y_train = np.frombuffer(f.read(), dtype = np.uint8, offset = 8)\r\n",
        "\r\n",
        "print(y_train.shape)\r\n",
        "\r\n",
        "with gzip.open('/content/mnist/t10k-images-idx3-ubyte.gz', 'rb') as f:\r\n",
        "    x_test = np.frombuffer(f.read(), dtype = np.uint8, offset = 16)\r\n",
        "\r\n",
        "x_test = x_test.reshape(-1, 28 * 28)\r\n",
        "print(x_test.shape)\r\n",
        "\r\n",
        "with gzip.open('/content/mnist/t10k-labels-idx1-ubyte.gz', 'rb') as f:\r\n",
        "    y_test = np.frombuffer(f.read(), dtype = np.uint8, offset = 8)\r\n",
        "\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n",
            "(10000, 784)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0mUjsUg_sdI",
        "outputId": "607ea823-77d5-4474-e50a-c1cac13ab12c"
      },
      "source": [
        "# 기본적으로 MNIST는 label 값이 0부터 9까지로 구성되어 있다.\r\n",
        "# p. 116의 load_mnist 코드에서는 one_hot_label = True로 지정하는데 이는 label을 one-hot encoding으로 바꾼다는 얘기다.\r\n",
        "# 따라서, one-hot encoding을 진행해준다.\r\n",
        "\r\n",
        "y_test_one = np.zeros((y_test.size, 10))\r\n",
        "\r\n",
        "# One hot Encoding\r\n",
        "for index, label in enumerate(y_test):\r\n",
        "    # 먼저 몇 번째 label인지에 대한 index를 가지고 위치를 찾은 뒤,\r\n",
        "    # 해당 label 위치만 1로 만들어주면 된다.\r\n",
        "    y_test_one[index][label] = 1\r\n",
        "\r\n",
        "# one-hot encoding 확인\r\n",
        "print(\"첫 번째 라벨: \", y_test[0])\r\n",
        "print(\"두 번째 라벨: \", y_test[1])\r\n",
        "print(\"one-hot encoding 후 첫 번째 라벨: \", y_test_one[0])\r\n",
        "print(\"one hot encoding 후 두 번째 라벨: \", y_test_one[1])\r\n",
        "\r\n",
        "\r\n",
        "y_train_one = np.zeros((y_train.size, 10))\r\n",
        "\r\n",
        "for index, label in enumerate(y_train):\r\n",
        "    y_train_one[index][label] = 1\r\n",
        "\r\n",
        "# one-hot encoding 확인\r\n",
        "print(\"첫 번째 라벨: \", y_train[0])\r\n",
        "print(\"두 번째 라벨: \", y_train[1])\r\n",
        "print(\"one-hot encoding 후 첫 번째 라벨: \", y_train_one[0])\r\n",
        "print(\"one hot encoding 후 두 번째 라벨: \", y_train_one[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "첫 번째 라벨:  7\n",
            "두 번째 라벨:  2\n",
            "one-hot encoding 후 첫 번째 라벨:  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "one hot encoding 후 두 번째 라벨:  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "첫 번째 라벨:  5\n",
            "두 번째 라벨:  0\n",
            "one-hot encoding 후 첫 번째 라벨:  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "one hot encoding 후 두 번째 라벨:  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0JDRwjtBJKd",
        "outputId": "d24a6de5-76a4-4516-fba3-8cf3d0e92cde"
      },
      "source": [
        "train_size = x_train.shape[0]\r\n",
        "batch_size = 10\r\n",
        "batch_mask = np.random.choice(train_size, batch_size)\r\n",
        "\r\n",
        "# train 전체 데이터 중 10개만 뽑는것\r\n",
        "print(batch_mask)\r\n",
        "\r\n",
        "\r\n",
        "x_batch = x_train[batch_mask]\r\n",
        "y_batch = y_train_one[batch_mask]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[27343 20254 25522  7079 45884 24418  8989 10208 33049 36409]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnpUaMZIEAtI"
      },
      "source": [
        "## 4.2.4 (배치용) 교차 엔트로피 오차 구현하기(p. 118)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgF-T-gVGV-W",
        "outputId": "36814f75-99c0-43fe-c99b-c057bef1e01f"
      },
      "source": [
        "# 2개짜리 예시로 한번 실행시켜보자.\r\n",
        "t = np.array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\r\n",
        "\r\n",
        "y = np.array([[0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0], [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]])\r\n",
        "\r\n",
        "# np.log(y)를 실행하면, 모델에서 나온 예측값인 y의 모든 값에 log가 씌워진다.\r\n",
        "print(\"np.log(y): \", np.log(y + 1e-7))\r\n",
        "\r\n",
        "\r\n",
        "# t * np.log(y)를 실행하면, 정답에 해당하는 예측값만 남게 된다.\r\n",
        "print(\"t * np.log(t) : \", t * np.log(y + 1e-7))\r\n",
        "\r\n",
        "# -np.sum() 까지 붙여주면, 완전한 CE의 식이 완성된다. 그리고 2개 배치로 계산했으므로, 2로 나눠준다.\r\n",
        "print(\"2 batch CE: \", -np.sum(t * np.log(y + 1e-7)) / 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "np.log(y):  [[ -2.30258409  -2.99573027  -0.51082546 -16.11809565  -2.99573027\n",
            "   -2.30258409 -16.11809565  -2.30258409 -16.11809565 -16.11809565]\n",
            " [ -2.30258409  -2.99573027  -2.30258409 -16.11809565  -2.99573027\n",
            "   -2.30258409 -16.11809565  -0.51082546 -16.11809565 -16.11809565]]\n",
            "t * np.log(t) :  [[-0.         -0.         -0.51082546 -0.         -0.         -0.\n",
            "  -0.         -0.         -0.         -0.        ]\n",
            " [-0.         -0.         -2.30258409 -0.         -0.         -0.\n",
            "  -0.         -0.         -0.         -0.        ]]\n",
            "2 batch CE:  1.406704775046942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbJIsXGWBZ-X"
      },
      "source": [
        "def cross_entropy_error(y, t):\r\n",
        "    # 해당 코드 없어도 잘 돌아가는데...?\r\n",
        "    #if y.ndim == 1:\r\n",
        "    #    t = t.reshape(1, t.size)\r\n",
        "    #    y = y.reshape(1, y.size)\r\n",
        "\r\n",
        "    batch_size = y.shape[0]\r\n",
        "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmUKHe_VH3GU",
        "outputId": "0b2f2a1a-0122-4315-a8e1-5c539c0f2440"
      },
      "source": [
        "# y와 t가 1차원인 경우\r\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "\r\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\r\n",
        "\r\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0510825457099338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC42OmncN4lW",
        "outputId": "1f788915-ad6e-4006-eb87-cb52c787a6b4"
      },
      "source": [
        "# y와 t가 2차원(배치)의 형태인 경우\r\n",
        "t = np.array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\r\n",
        "\r\n",
        "y = np.array([[0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0], [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]])\r\n",
        "\r\n",
        "cross_entropy_error(y, t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.406704775046942"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKv71SD0OyCe"
      },
      "source": [
        "# (추가) sample weight로 예측한 다음, CE 구해보기\r\n",
        "\r\n",
        "해당 내용은 책에 없었지만....\r\n",
        "\r\n",
        "Chapter 3에서 제공했던 sample weight를 이용하면\r\n",
        "\r\n",
        "전체 데이터 중 임의의 10개 데이터에 대해 예측이 가능하니\r\n",
        "\r\n",
        "이걸 통해서 예측해보고 CE를 계산해볼 수 있겠다고 생각했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hik8ewQDOaUv",
        "outputId": "df80b01a-d9ad-4ee4-d72e-643a35fae5a0"
      },
      "source": [
        "# Chapter 3에서 제공되었던 sample weight를 끌고옵니다.\r\n",
        "# https://github.com/WegraLee/deep-learning-from-scratch/raw/master/ch03/sample_weight.pkl\r\n",
        "urllib.request.urlretrieve('https://github.com/WegraLee/deep-learning-from-scratch/raw/master/ch03/sample_weight.pkl', os.path.join(save_folder, 'sample_weight.pkl'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/mnist/sample_weight.pkl',\n",
              " <http.client.HTTPMessage at 0x7f93da94b198>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF2_V232PHzo"
      },
      "source": [
        "# From Chapter 3\r\n",
        "\r\n",
        "def init_network():\r\n",
        "    with open('/content/mnist/sample_weight.pkl', 'rb') as f:\r\n",
        "        network = pickle.load(f)\r\n",
        "    return network\r\n",
        "\r\n",
        "def sigmoid(x):\r\n",
        "    return 1 / (1 + np.exp(-x))\r\n",
        "\r\n",
        "def softmax(x):\r\n",
        "    c = np.max(x)\r\n",
        "    x_ = np.exp(x - c)\r\n",
        "    y = x_ / np.sum(x_)\r\n",
        "    return y\r\n",
        "\r\n",
        "def predict(network, x):\r\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\r\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\r\n",
        "\r\n",
        "    a1 = np.dot(x, W1) + b1\r\n",
        "    z1 = sigmoid(a1)\r\n",
        "    a2 = np.dot(z1, W2) + b2\r\n",
        "    z2 = sigmoid(a2)\r\n",
        "    a3 = np.dot(z2, W3) + b3\r\n",
        "    y = softmax(a3)\r\n",
        "\r\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZz2qbjLPhu0",
        "outputId": "7e2a439b-9449-41ae-fab1-4b17db898204"
      },
      "source": [
        "network = init_network()\r\n",
        "y_pred = []\r\n",
        "\r\n",
        "for i in range(len(x_batch)):\r\n",
        "    # 저장된 가중치로 예측\r\n",
        "    y = predict(network, x_batch[i])\r\n",
        "\r\n",
        "    # y_pred에 예측 결과를 append\r\n",
        "    y_pred.append(list(y))\r\n",
        "\r\n",
        "print(\"예측값: \", \"\\n\", y_pred)\r\n",
        "print(\"실제 정답: \", \"\\n\", y_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측값:  \n",
            " [[0.9941385, 7.974671e-08, 0.0018961073, 0.00024021456, 1.6724672e-06, 0.0027220382, 0.0007191038, 4.3468357e-05, 0.00020851899, 3.0421752e-05], [2.0752004e-06, 2.842873e-06, 9.332469e-06, 4.7508674e-05, 0.09200752, 0.00049310975, 7.632297e-06, 0.0005432701, 0.0032558737, 0.9036309], [5.7927142e-08, 2.3618188e-06, 0.00012444034, 0.00013507176, 3.5615338e-07, 2.847703e-07, 3.8802897e-10, 0.999485, 5.582725e-07, 0.000251846], [3.526004e-05, 3.8636913e-06, 0.9996631, 1.91554e-05, 2.2146662e-06, 1.2291339e-06, 0.00025169662, 1.7279611e-06, 2.1653892e-05, 9.7458226e-08], [0.0011850706, 9.249875e-05, 0.0029870025, 0.020591918, 6.732489e-05, 0.00954383, 0.00021795818, 1.7268123e-06, 0.9647351, 0.0005775862], [0.00026207571, 1.2876336e-06, 0.9976041, 0.0018601303, 1.2089256e-08, 4.4480953e-06, 2.409255e-06, 9.623329e-06, 0.00025571242, 2.5326565e-07], [4.1881547e-11, 0.99939525, 0.00010069904, 7.468909e-05, 8.3493194e-07, 3.6736162e-06, 4.8312495e-06, 2.183928e-05, 0.0003904526, 7.68644e-06], [6.029647e-08, 9.614288e-07, 4.701904e-06, 1.7593919e-05, 0.0024253887, 1.4487878e-06, 1.17704474e-07, 0.0006064206, 0.0002595977, 0.99668366], [0.00045134005, 3.4560457e-05, 0.004997518, 0.99205047, 7.881864e-08, 0.0010033544, 7.546811e-07, 8.81118e-06, 0.001447962, 5.0570275e-06], [0.00527592, 4.1293883e-05, 0.03010764, 0.06576152, 0.0005242799, 0.0083909305, 7.3589035e-05, 0.004126997, 0.7527111, 0.13298668]]\n",
            "실제 정답:  \n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO8s6w3zQ0qg",
        "outputId": "92def062-9016-4b22-a9da-cbef10ebd3aa"
      },
      "source": [
        "# sample weight로 예측된 값과 실제 정답과의 CE 계산\r\n",
        "cross_entropy_error(np.array(y_pred), np.array(y_batch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28799916663265324"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwX_ERagPzVy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}